{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-39., -20.,  29., ..., -12.,  19.,  20.],\n",
       "        [-29.,  -5.,  15., ...,  31.,  34.,  -6.],\n",
       "        [ 25.,  -5.,  10., ..., -21., -49.,  43.],\n",
       "        ...,\n",
       "        [  7.,  72., 809., ...,  -2.,  22.,  -1.],\n",
       "        [ 32.,  13., -12., ...,  10., -12.,  -8.],\n",
       "        [  5., -26.,   3., ...,  -6., -20.,  -1.]]),\n",
       " array([[27., 16., 15., ..., 19., 11., 25.],\n",
       "        [ 7., 20., 39., ..., 34., -1.,  0.],\n",
       "        [12., 34.,  5., ..., 39., 28., 34.],\n",
       "        ...,\n",
       "        [ 2., 22., 17., ...,  5.,  8.,  1.],\n",
       "        [ 2., 14., 10., ..., 43.,  2.,  0.],\n",
       "        [ 5.,  5., 15., ...,  7., 37., 59.]]),\n",
       " array([[27., 16., 15., ..., 19., 11., 25.],\n",
       "        [ 7., 20., 39., ..., 34., -1.,  0.],\n",
       "        [12., 34.,  5., ..., 39., 28., 34.],\n",
       "        ...,\n",
       "        [ 2., 22., 17., ...,  5.,  8.,  1.],\n",
       "        [ 2., 14., 10., ..., 43.,  2.,  0.],\n",
       "        [ 5.,  5., 15., ...,  7., 37., 59.]]),\n",
       " array([[0.02083333, 0.02083333, 0.02083333, ..., 0.02083333, 0.02083333,\n",
       "         0.02083333],\n",
       "        [0.02083333, 0.02083333, 0.02083333, ..., 0.02083333, 0.02083333,\n",
       "         0.02083333],\n",
       "        [0.02083333, 0.02083333, 0.02083333, ..., 0.02083333, 0.02083333,\n",
       "         0.02083333],\n",
       "        ...,\n",
       "        [0.02083333, 0.02083333, 0.02083333, ..., 0.02083333, 0.02083333,\n",
       "         0.02083333],\n",
       "        [0.02083333, 0.02083333, 0.02083333, ..., 0.02083333, 0.02083333,\n",
       "         0.02083333],\n",
       "        [0.02083333, 0.02083333, 0.02083333, ..., 0.02083333, 0.02083333,\n",
       "         0.02083333]]),\n",
       " array([[0.02083333, 0.02083333, 0.02083333, ..., 0.02083333, 0.02083333,\n",
       "         0.02083333],\n",
       "        [0.02083333, 0.02083333, 0.02083333, ..., 0.02083333, 0.02083333,\n",
       "         0.02083333],\n",
       "        [0.02083333, 0.02083333, 0.02083333, ..., 0.02083333, 0.02083333,\n",
       "         0.02083333],\n",
       "        ...,\n",
       "        [0.02083333, 0.02083333, 0.02083333, ..., 0.02083333, 0.02083333,\n",
       "         0.02083333],\n",
       "        [0.02083333, 0.02083333, 0.02083333, ..., 0.02083333, 0.02083333,\n",
       "         0.02083333],\n",
       "        [0.02083333, 0.02083333, 0.02083333, ..., 0.02083333, 0.02083333,\n",
       "         0.02083333]]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from astropy.table import Table\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from ipywidgets import Button, Layout, jslink, IntText, IntSlider, interactive, interact, HBox, Layout, VBox\n",
    "from astropy.modeling.functional_models import Gaussian2D, Gaussian1D\n",
    "import os\n",
    "from IPython.display import display, clear_output\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import inspect\n",
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import wraps\n",
    "import inspect\n",
    "from scipy.sparse import dia_matrix\n",
    "from scipy.interpolate import interpn\n",
    "from scipy.special import erf\n",
    "from astropy.modeling.functional_models import Gaussian2D\n",
    "import pandas as pd\n",
    "import functools\n",
    "np.seterr(invalid='ignore')\n",
    " \n",
    "\n",
    "sheet_id = \"1Ox0uxEm2TfgzYA6ivkTpU4xrmN5vO5kmnUPdCSt73uU\"\n",
    "sheet_name = \"instruments.csv\"\n",
    "url = f\"https://docs.google.com/spreadsheets/d/{sheet_id}/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
    "try:\n",
    "    instruments = Table.from_pandas(pd.read_csv(url))\n",
    "except Exception:\n",
    "    instruments = Table.read(\"Instruments.csv\")\n",
    "instruments = instruments[instruments.colnames]\n",
    "instruments_dict ={ name:{key:float(val) for key, val in zip(instruments[\"Charact.\"][:],instruments[name][:])} for name in instruments.colnames[3:]}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def float_to_latex(mumber):\n",
    "    try:\n",
    "        return \"$\\,\"+ (\"%.1E\"%(mumber)).replace(\"E\",\" \\,10^{\")+\"}$\"\n",
    "    except TypeError as e:\n",
    "        print(e,mumber)\n",
    "    # return (\"%.1E\"%(mumber)).replace(\"E\",\" 10$^{\")+\"}$\"\n",
    "\n",
    "def rsetattr(obj, attr, val):\n",
    "    pre, _, post = attr.rpartition('.')\n",
    "    return setattr(rgetattr(obj, pre) if pre else obj, post, val)\n",
    "\n",
    "\n",
    "def rgetattr(obj, attr, *args):\n",
    "    def _getattr(obj, attr):\n",
    "        return getattr(obj, attr, *args)\n",
    "    return functools.reduce(_getattr, [obj] + attr.split('.'))\n",
    "\n",
    "\n",
    "def convert_LU2ergs(LU,wave_nm,pixel_size_arcsec):\n",
    "    wave =wave_nm * 1e-7 #/ (1+redshift)\n",
    "    Energy = 6.62e-27 * 3e10 / wave\n",
    "    angle = pixel_size_arcsec * np.pi / (180 * 3600)\n",
    "    flux_ergs = LU * Energy * angle * angle\n",
    "    return flux_ergs\n",
    "\n",
    "def convert_ergs2LU(flux_ergs,wave_nm,pixel_size_arcsec):\n",
    "    wave =wave_nm * 1e-7 #/ (1+redshift)\n",
    "    Energy = 6.62e-27 * 3e10 / wave\n",
    "    angle =  pixel_size_arcsec * np.pi / (180 * 3600)\n",
    "    # flux_ergs = LU * Energy * angle * angle\n",
    "    LU = flux_ergs/ (Energy  * angle * angle)\n",
    "    return LU\n",
    "\n",
    "def initializer(func):\n",
    "    \"\"\"\n",
    "    Automatically assigns the parameters.\n",
    "\n",
    "    >>> class process:\n",
    "    ...     @initializer\n",
    "    ...     def __init__(self, cmd, reachable=False, user='root'):\n",
    "    ...         pass\n",
    "    >>> p = process('halt', True)\n",
    "    >>> p.cmd, p.reachable, p.user\n",
    "    ('halt', True, 'root')\n",
    "    \"\"\"\n",
    "    # names, varargs, keywords, defaults = inspect.getargspec(func)\n",
    "    names, varargs, keywords, defaults,_,_,_ = inspect.getfullargspec(func)\n",
    "\n",
    "    @wraps(func)\n",
    "    def wrapper(self, *args, **kargs):\n",
    "        for name, arg in list(zip(names[1:], args)) + list(kargs.items()):\n",
    "            setattr(self, name, arg)\n",
    "\n",
    "        for name, default in zip(reversed(names), reversed(defaults)):\n",
    "            if not hasattr(self, name):\n",
    "                setattr(self, name, default)\n",
    "\n",
    "        func(self, *args, **kargs)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "# Initialization of the thresholding functions. So that files are not read several times\n",
    "n=10\n",
    "type_=\"\" #\"new_\" #\"\"\n",
    "#new is for when we don't use fraction and use RN (false I think), \"\" is with fraction true positives and RN/gain, seems better \n",
    "path=\"\"\n",
    "# path = \"/Users/Vincent/Github/fireball2-etc/notebooks/\"\n",
    "table_threshold = fits.open(path+\"interpolate/%sthreshold_%s.fits\"%(type_,n))[0].data\n",
    "table_snr = fits.open(path+\"interpolate/%ssnr_max_%s.fits\"%(type_,n))[0].data\n",
    "table_fraction_rn = fits.open(path+\"interpolate/%sfraction_rn_%s.fits\"%(type_,n))[0].data\n",
    "table_fraction_flux = fits.open(path+\"interpolate/%sfraction_flux_%s.fits\"%(type_,n))[0].data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def variable_smearing_kernels(image, smearing=1.5, SmearExpDecrement=50000):\n",
    "    \"\"\"Creates variable smearing kernels for inversion\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    smearing_length = smearing * np.exp(-image / SmearExpDecrement)\n",
    "    smearing_kernels = np.exp(-np.arange(6)[:, np.newaxis, np.newaxis] / smearing_length)\n",
    "    smearing_kernels /= smearing_kernels.sum(axis=0)\n",
    "    return smearing_kernels   \n",
    "\n",
    "\n",
    "class Observation:\n",
    "    @initializer\n",
    "    # def __init__(self, instrument=\"FIREBall-2 2023\", Atmosphere=0.5, Throughput=0.13*0.9, exposure_time=50, counting_mode=False, Signal=1e-16, EM_gain=1400, RN=109, CIC_charge=0.005, Dard_current=0.08, Sky=10000, readout_time=1.5, extra_background = 0,acquisition_time = 2,smearing=0,i=25,plot_=False,temperature=-100,n=n,PSF_RMS_mask=5, PSF_RMS_det=8, QE = 0.45,cosmic_ray_loss_per_sec=0.005,PSF_source=16,lambda_stack=1,Slitwidth=5,Bandwidth=200,Collecting_area=1,Δx=0,Δλ=0,pixel_scale=np.nan, Spectral_resolution=np.nan, dispersion=np.nan,Line_width=np.nan,wavelength=np.nan, pixel_size=np.nan,len_xaxis=50):#,photon_kept=0.7#, flight_background_damping = 0.9\n",
    "    def __init__(self, instrument=\"FIREBall-2 2023\", Atmosphere=0.5, Throughput=0.13, exposure_time=50, counting_mode=False, Signal=1e-17, EM_gain=1500, RN=40, CIC_charge=0.005, Dard_current=1, Sky=2e-18, readout_time=5, extra_background = 0.5,acquisition_time = 2,smearing=0.50,i=25,plot_=False,temperature=-100,n=n,PSF_RMS_mask=2.5, PSF_RMS_det=3, QE = 0.4,cosmic_ray_loss_per_sec=0.005,PSF_source=16,lambda_stack=0.21,Slitwidth=6,Bandwidth=100,Collecting_area=0.707,Δx=0,Δλ=0,pixel_scale=1.1, Spectral_resolution=1300, dispersion=0.21,Line_width=15,wavelength=200, pixel_size=13,len_xaxis=50,Slitlength=10):#,photon_kept=0.7#, flight_background_damping = 0.9\n",
    "        \"\"\"\n",
    "        ETC calculator: computes the noise budget at the detector level based on instrument/detector parameters\n",
    "        This is currently optimized for slit spectrographs and EMCCD but could be pretty easily generalized to other instrument type if needed\n",
    "        \"\"\"\n",
    "\n",
    "        self.Signal = Gaussian2D(amplitude=self.Signal,x_mean=0,y_mean=0,x_stddev=self.PSF_source,y_stddev=4,theta=0)(self.Δx,self.Δλ)\n",
    "        # print(\"\\nAtmosphere\",self.Atmosphere, \"\\nThroughput=\",self.Throughput,\"\\nSky=\",Sky, \"\\nacquisition_time=\",acquisition_time,\"\\ncounting_mode=\",counting_mode,\"\\nSignal=\",Signal,\"\\nEM_gain=\",EM_gain,\"RN=\",RN,\"CIC_charge=\",CIC_charge,\"Dard_current=\",Dard_current,\"\\nreadout_time=\",readout_time,\"\\n_smearing=\",smearing,\"\\nextra_background=\",extra_background,\"\\ntemperature=\",temperature,\"\\nPSF_RMS_mask=\",PSF_RMS_mask,\"\\nPSF_RMS_det=\",PSF_RMS_det,\"\\nQE=\",QE,\"\\ncosmic_ray_loss_per_sec=\",self.cosmic_ray_loss_per_sec,\"\\nlambda_stack\",self.lambda_stack,\"\\nSlitwidth\",self.Slitwidth, \"\\nBandwidth\",self.Bandwidth,\"\\nPSF_source\",self.PSF_source,\"\\nCollecting_area\",self.Collecting_area)\n",
    "        # print(\"\\Collecting_area\",self.Collecting_area, \"\\nΔx=\",self.Δx,\"\\nΔλ=\",Δλ, \"\\napixel_scale=\",pixel_scale,\"\\nSpectral_resolution=\",Spectral_resolution,\"\\ndispersion=\",dispersion,\"\\nLine_width=\",Line_width,\"wavelength=\",wavelength,\"pixel_size=\",pixel_size)\n",
    "        \n",
    "        # Simple hack to me able to use UV magnitudes (not used for the ETC)\n",
    "        if np.max([self.Signal])>1:\n",
    "            self.Signal = 10**(-(Signal-20.08)/2.5)*2.06*1E-16\n",
    "        #TODO be sure we account for potential 2.35 ratio here\n",
    "        #convolve input flux by instrument PSF\n",
    "        self.Signal *= (erf(self.PSF_source / (2 * np.sqrt(2) * self.PSF_RMS_det)) )\n",
    "        #convolve input flux by spectral resolution\n",
    "        # self.spectro_resolution_A = self.wavelength * self.spectral\n",
    "        self.Signal *= (erf(self.Line_width / (2 * np.sqrt(2) * 10*self.wavelength/self.Spectral_resolution)) )\n",
    "\n",
    "\n",
    "        if ~np.isnan(self.Slitwidth).all():\n",
    "            # assess flux fraction going through slit\n",
    "            self.flux_fraction_slit = (1+erf(self.Slitwidth/(2*np.sqrt(2)*self.PSF_RMS_mask)))-1\n",
    "        else:\n",
    "            self.flux_fraction_slit = 1\n",
    "        \n",
    "        self.resolution_element= self.PSF_RMS_det * 2.35 /self.pixel_scale  # in pix (before it was in arcseconds)\n",
    "        self.PSF_lambda_pix = self.wavelength / self.Spectral_resolution / self.dispersion\n",
    "\n",
    "        red, blue, violet, yellow, green, pink, grey  = '#E24A33','#348ABD','#988ED5','#FBC15E','#8EBA42','#FFB5B8','#777777'\n",
    "        # self.colors= ['#E24A33','#348ABD','#988ED5','#FBC15E','#FFB5B8','#8EBA42','#777777']\n",
    "        # self.colors= ['#E24A33','#348ABD','#988ED5','#FBC15E','#8EBA42','#FFB5B8','#777777']\n",
    "        self.colors= [red, violet, yellow  ,blue, green, pink, grey ]\n",
    "        # self.Sky_CU =  convert_ergs2LU(self.Sky_,self.wavelength,self.pixel_scale)\n",
    "        # self.Sky_ = self.Sky_CU*self.lu2ergs# ergs/cm2/s/arcsec^2 \n",
    "\n",
    "        self.ENF = 1 if self.counting_mode else 2 # Excess Noise Factor \n",
    "        self.CIC_noise = np.sqrt(CIC_charge * self.ENF) \n",
    "        self.Dark_current_f = self.Dard_current * self.exposure_time / 3600 # e/pix/frame\n",
    "        self.Dark_current_noise =  np.sqrt(self.Dark_current_f * self.ENF)\n",
    "        \n",
    "        # For now we put the regular QE without taking into account the photon kept fracton, because then infinite loop. \n",
    "        # Two methods to compute it: interpolate_optimal_threshold & compute_optimal_threshold\n",
    "        self.pixel_size_arcsec = self.pixel_scale\n",
    "        # self.pixel_scale  = (self.pixel_scale*np.pi/180/3600) #go from arcsec/pix to str/pix \n",
    "        self.arcsec2str = (np.pi/180/3600)**2\n",
    "        self.Sky_CU = convert_ergs2LU(self.Sky, self.wavelength,self.pixel_size_arcsec) \n",
    "        # self.Sky_ = convert_LU2ergs(self.Sky_CU, self.wavelength,self.pixel_size_arcsec) \n",
    "        # self.Collecting_area *= 100 * 100#m2 to cm2\n",
    "        # TODO use astropy.unit\n",
    "        if self.counting_mode:\n",
    "            self.factor_CU2el =  self.QE * self.Throughput * self.Atmosphere  *    (self.Collecting_area * 100 * 100)  * self.Slitwidth * self.arcsec2str  * self.dispersion\n",
    "            self.sky = self.Sky_CU*self.factor_CU2el*self.exposure_time  # el/pix/frame\n",
    "            self.Sky_noise_pre_thresholding = np.sqrt(self.sky * self.ENF) \n",
    "            self.signal_pre_thresholding = self.Signal*self.factor_CU2el*self.exposure_time  # el/pix/frame\n",
    "            self.n_threshold, self.Photon_fraction_kept, self.RN_fraction_kept, self.gain_thresholding = self.interpolate_optimal_threshold(plot_=plot_, i=i)#,flux=self.signal_pre_thresholding)\n",
    "            # self.n_threshold, self.Photon_fraction_kept, self.RN_fraction_kept, self.gain_thresholding = self.compute_optimal_threshold(plot_=plot_, i=i,flux=self.signal_pre_thresholding)\n",
    "        else:\n",
    "            self.n_threshold, self.Photon_fraction_kept, self.RN_fraction_kept, self.gain_thresholding = np.zeros(self.len_xaxis),np.ones(self.len_xaxis),np.ones(self.len_xaxis), np.zeros(self.len_xaxis)\n",
    "        # The faction of detector lost by cosmic ray masking (taking into account ~5-10 impact per seconds and around 2000 pixels loss per impact (0.01%))\n",
    "        self.cosmic_ray_loss = np.minimum(self.cosmic_ray_loss_per_sec*(self.exposure_time+self.readout_time/2),1)\n",
    "        self.QE_efficiency = self.Photon_fraction_kept * self.QE\n",
    "        # TODO verify that indeed it should not depend on self.pixel_scale**2 \n",
    "        # Compute ratio to convert CU to el/pix \n",
    "        if np.isnan(self.Slitwidth).all():\n",
    "            # If instrument is not a spectro?\n",
    "            self.factor_CU2el = self.QE_efficiency * self.Throughput * self.Atmosphere  *    (self.Collecting_area * 100 * 100)   * self.Bandwidth  * self.arcsec2str# *self.pixel_scale**2 but here it's total number of electrons we don't know if it is per A or not and so if we need to devide by dispersion: 1LU/A = .. /A. OK So we need to know if sky is LU or LU/A            \n",
    "        else:\n",
    "            self.factor_CU2el = self.QE_efficiency * self.Throughput * self.Atmosphere  *    (self.Collecting_area * 100 * 100)  * self.Slitwidth * self.arcsec2str  * self.dispersion  #*self.pixel_scale**2  but here it's total number of electrons we don't know if it is per A or not and so if we need to devide by dispersion: 1LU/A = .. /A. OK So we need to know if sky is LU or LU/A\n",
    "        \n",
    "\n",
    "        self.sky = self.Sky_CU*self.factor_CU2el*self.exposure_time  # el/pix/frame\n",
    "        self.Sky_noise = np.sqrt(self.sky * self.ENF) \n",
    "            \n",
    "        # TODO in counting mode, Photon_fraction_kept should also be used for CIC\n",
    "        self.RN_final = self.RN  * self.RN_fraction_kept / self.EM_gain \n",
    "        self.Additional_background = self.extra_background/3600 * self.exposure_time# e/pix/exp\n",
    "        self.Additional_background_noise = np.sqrt(self.Additional_background * self.ENF)\n",
    "        \n",
    "        # number of images taken during one field acquisition (~2h)\n",
    "        self.N_images = self.acquisition_time*3600/(self.exposure_time + self.readout_time)\n",
    "        self.N_images_true = self.N_images * (1-self.cosmic_ray_loss)\n",
    "\n",
    "        self.Signal_LU = convert_ergs2LU(self.Signal,self.wavelength,self.pixel_size_arcsec)\n",
    "        # if 1==0: # if line is totally resolved (for cosmic web for instance)\n",
    "        #     self.Signal_el =  self.Signal_LU*self.factor_CU2el*self.exposure_time * self.flux_fraction_slit  / self.spectral_resolution_pixel # el/pix/frame#     Signal * (sky / Sky_)  #el/pix\n",
    "        # else: # if line is unresolved for QSO for instance\n",
    "        self.Signal_el =  self.Signal_LU * self.factor_CU2el * self.exposure_time * self.flux_fraction_slit   # el/pix/frame#     Signal * (sky / Sky_)  #el/pix\n",
    "        # print(self.flux_fraction_slit)\n",
    "\n",
    "        self.signal_noise = np.sqrt(self.Signal_el * self.ENF)     #el / resol/ N frame\n",
    "\n",
    "        self.N_resol_element_A = self.lambda_stack / self.dispersion# / (1/self.dispersion)#/ (10*self.wavelength/self.Spectral_resolution) # should work even when no spectral resolution\n",
    "        self.factor = np.sqrt(self.N_images_true) * self.resolution_element * np.sqrt(self.N_resol_element_A)\n",
    "        self.Signal_resolution = self.Signal_el * self.factor**2# el/N exposure/resol\n",
    "        self.signal_noise_nframe = self.signal_noise * self.factor\n",
    "        self.Total_noise_final = self.factor*np.sqrt(self.signal_noise**2 + self.Dark_current_noise**2  + self.Additional_background_noise**2 + self.Sky_noise**2 + self.CIC_noise**2 + self.RN_final**2   ) #e/  pix/frame\n",
    "        self.SNR = self.Signal_resolution / self.Total_noise_final\n",
    "        \n",
    "        if type(self.Total_noise_final + self.Signal_resolution) == np.float64:\n",
    "            n=0\n",
    "        else:\n",
    "            n =len(self.Total_noise_final + self.Signal_resolution) \n",
    "        if n>1:\n",
    "            for name in [\"signal_noise\",\"Dark_current_noise\", \"Additional_background_noise\",\"Sky_noise\", \"CIC_noise\", \"RN_final\",\"Signal_resolution\",\"Signal_el\",\"sky\",\"CIC_charge\",\"Dark_current_f\",\"RN\",\"Additional_background\"]:\n",
    "                setattr(self, name, getattr(self,name)*np.ones(n))\n",
    "        self.factor = self.factor*np.ones(n) if type(self.factor)== np.float64 else self.factor\n",
    "        self.noises = np.array([self.signal_noise*self.factor,  self.Dark_current_noise*self.factor,  self.Sky_noise*self.factor, self.RN_final*self.factor, self.CIC_noise*self.factor, self.Additional_background_noise*self.factor, self.Signal_resolution]).T\n",
    "        self.electrons_per_pix =  np.array([self.Signal_el,  self.Dark_current_f,  self.sky,  self.RN_final, self.CIC_charge, self.Additional_background]).T\n",
    "        self.names = [\"Signal\",\"Dark current\", \"Sky\", \"Read noise\",\"CIC\", \"Extra background\"]\n",
    "        self.snrs=self.Signal_resolution /self.Total_noise_final\n",
    "\n",
    "        if np.ndim(self.noises)==2:\n",
    "            self.percents =  100* np.array(self.noises).T[:-1,:]**2/self.Total_noise_final**2\n",
    "        else:\n",
    "            self.percents =  100* np.array(self.noises).T[:-1]**2/self.Total_noise_final**2            \n",
    "        \n",
    "        self.el_per_pix = self.Signal_el + self.sky + self.CIC_charge +  self.Dark_current_f\n",
    "        n_sigma = 5\n",
    "        self.signal_nsig_e_resol_nframe = (n_sigma**2 * self.ENF + n_sigma**2 * np.sqrt(4*self.Total_noise_final**2 - 4*self.signal_noise_nframe**2 + self.ENF**2*n_sigma**2))/2\n",
    "        self.eresolnframe2lu = self.Signal_LU/self.Signal_resolution\n",
    "        self.signal_nsig_LU = self.signal_nsig_e_resol_nframe * self.eresolnframe2lu\n",
    "        self.signal_nsig_ergs = convert_LU2ergs(self.signal_nsig_LU, self.wavelength,self.pixel_size_arcsec) # self.signal_nsig_LU * self.lu2ergs\n",
    "        self.extended_source_5s = self.signal_nsig_ergs * (self.pixel_scale*self.PSF_RMS_det)**2\n",
    "        self.point_source_5s = self.extended_source_5s * 1.30e57\n",
    "        self.time2reach_n_sigma_SNR = self.acquisition_time *  np.square(n_sigma / self.snrs)\n",
    "        # print(\"factor=\",self.factor[self.i])\n",
    "        # print(\"N_images_true=\",np.sqrt(self.N_images_true)[self.i] )\n",
    "        # print(\"resolution_element=\", self.resolution_element)\n",
    "        # print(\"N_resol_element_A=\",np.sqrt(self.N_resol_element_A))\n",
    "        # print(\"lambda_stack=\",self.lambda_stack)\n",
    "        # print(\"dispersion=\",self.dispersion)\n",
    "        # print(\"cosmic_ray_loss=\",np.sqrt(self.cosmic_ray_loss)[self.i])\n",
    "        # print(\"N_images=\",np.sqrt(self.N_images)[self.i])\n",
    "\n",
    "        #TODO change this ratio of 1.30e57\n",
    "        # from astropy.cosmology import Planck15 as cosmo\n",
    "        # 4*np.pi* (cosmo.luminosity_distance(z=0.7).to(\"cm\").value)**2 = 2.30e57\n",
    "\n",
    "\n",
    "       \n",
    "\n",
    "    def PlotNoise(self,title='',x='exposure_time', lw=8):\n",
    "        \"\"\"\n",
    "        Generate a plot of the evolution of the noise budget with one parameter:\n",
    "        exposure_time, Sky_CU, acquisition_time, Signal, EM_gain, RN, CIC_charge, Dard_current, readout_time, smearing, temperature, PSF_RMS_det, PSF_RMS_mask, QE, extra_background, cosmic_ray_loss_per_sec\n",
    "        \"\"\"\n",
    "        fig, axes= plt.subplots(4, 1, figsize=(12, 8), sharex=True) # fig, (ax1, ax2,ax3) = plt.subplots(3, 1, figsize=(12, 7), sharex=True) #figsize=(9, 5.5)\n",
    "        ax1, ax2,ax3, ax4  = axes\n",
    "        labels = ['%s: %0.3f (%0.1f%%)'%(name,self.electrons_per_pix[self.i,j],100*self.electrons_per_pix[self.i,j]/np.nansum(self.electrons_per_pix[self.i,:])) for j,name in enumerate(self.names)]\n",
    "\n",
    "        # ax1 \n",
    "        for i,(name,c) in enumerate(zip(self.names,self.colors)):\n",
    "            ax1.plot(getattr(self,x), self.noises[:,i]/self.factor,label='%s: %0.2f (%0.1f%%)'%(name,self.noises[self.i,i]/self.factor[self.i],self.percents[i,self.i]),lw=lw,alpha=0.8,c=c)\n",
    "        ax1.plot(getattr(self,x), np.nansum(self.noises[:,:-1],axis=1)/self.factor,label='%s: %0.2f (%0.1f%%)'%(\"Total\",np.nansum(self.noises[self.i,-1])/self.factor[self.i],np.nansum(self.percents[:,self.i])),lw=lw,alpha=0.4,c=\"k\")\n",
    "        ax1.legend(loc='upper right')\n",
    "        ax1.set_ylabel('Noise (e-/pix/exp)')\n",
    "\n",
    "        # ax1b = ax1.secondary_yaxis(\"right\", functions=( lambda x:  x * self.factor[self.i], lambda x:x / self.factor[self.i] ))\n",
    "        # self.ax1b = ax1b\n",
    "        # ax1b.set_ylabel(\"Noise (e-/res/N frames)\")#r\"%0.1f,%0.1f,%0.1f\"%(self.factor[self.i],self.resolution_element , np.sqrt(self.N_resol_element_A)))\n",
    "\n",
    "\n",
    "        # ax2 \n",
    "        ax2.grid(False)\n",
    "        self.stackplot1 = ax2.stackplot(getattr(self,x),  np.array(self.electrons_per_pix).T[:,:],alpha=0.7,colors=self.colors,labels=labels)\n",
    "        ax2.set_ylabel('e-/pix/frame')\n",
    "        ax2.legend(loc='upper right',title=\"Overall background: %0.3f (%0.1f%%)\"%(np.nansum(self.electrons_per_pix[self.i,1:]),100*np.nansum(self.electrons_per_pix[self.i,1:])/np.nansum(self.electrons_per_pix[self.i,:])))\n",
    "        ax2.set_xlim((getattr(self,x).min(),getattr(self,x).max()))\n",
    "\n",
    "\n",
    "        # ax2b = ax2.secondary_yaxis(\"right\", functions=( lambda x:  x * self.factor[self.i]**2, lambda x:x / self.factor[self.i]**2 ))\n",
    "        # self.ax2b = ax2b\n",
    "        # ax2b.set_ylabel(r\"%0.1f,%0.1f,%0.1f\"%(self.factor[self.i],self.resolution_element , np.sqrt(self.N_resol_element_A)))\n",
    "\n",
    "\n",
    "\n",
    "        # ax3\n",
    "        ax3.grid(False)\n",
    "        self.stackplot2 = ax3.stackplot(getattr(self,x), self.snrs * np.array(self.noises).T[:-1,:]**2/self.Total_noise_final**2,alpha=0.7,colors=self.colors)\n",
    "        ax3.set_ylim((0,np.nanmax(self.SNR)))\n",
    "        ax3.set_ylabel('SNR (res, N frames)')        \n",
    "\n",
    "        # ax3b = ax3.secondary_yaxis(\"right\", functions=( lambda x: x / self.factor[self.i]**2, lambda x: x * self.factor[self.i]**2))\n",
    "        # self.ax3b = ax3b\n",
    "        # ax3b.set_ylabel(r\" SNR(res/N frames\")\n",
    "\n",
    "\n",
    "\n",
    "        # ax4\n",
    "        ax4.plot(getattr(self,x), np.log10(self.extended_source_5s),\"-\",lw=lw-1,label=\"SNR=5 Flux/Pow on one elem resolution (%0.2f-%0.2f)\"%(np.log10(self.point_source_5s[self.i]),np.nanmin(np.log10(self.point_source_5s))),c=\"k\")\n",
    "        # if self.instrument==FIREBall:\n",
    "        if \"FIREBall\" in self.instrument:\n",
    "\n",
    "            ax4.plot(getattr(self,x), np.log10(self.extended_source_5s/np.sqrt(2)),\"-\",lw=lw-1,label=\"Two elem resolution (%0.2f-%0.2f)\"%(np.log10(self.point_source_5s[self.i]/np.sqrt(2)),np.nanmin(np.log10(self.point_source_5s/np.sqrt(2)))),c=\"grey\")\n",
    "            # ax4.plot(getattr(self,x), np.log10(self.extended_source_5s/np.sqrt(40)),\"-\",lw=lw-1,label=\"20 sources stacked on 2 res elem. (%0.2f-%0.2f)\"%(np.log10(self.point_source_5s[self.i]/np.sqrt(40)),np.nanmin(np.log10(self.point_source_5s/np.sqrt(40)))),c=\"lightgrey\")\n",
    "            # ax4.plot(getattr(self,x), np.log10(self.extended_source_5s/np.sqrt(2)/30),\"-\",lw=lw-1,label=\"Sources transported to high z: (%0.2f-%0.2f) \\ngain of factor 22-50 depending on line resolution\"%(np.log10(self.point_source_5s[self.i]/np.sqrt(2)/30),np.nanmin(np.log10(self.point_source_5s/np.sqrt(2)/30))),c=\"whitesmoke\")\n",
    "        T2 =  lambda x:np.log10(10**x/1.30e57)\n",
    "        self.pow_2018 = 42.95\n",
    "        self.pow_best = 41.74\n",
    "        ax4b = ax4.secondary_yaxis(\"right\", functions=(lambda x:np.log10(10**x * 1.30e57),T2))\n",
    "        if (\"FIREBall\" in self.instrument) & (1==0):\n",
    "            ax4.plot([getattr(self,x).min(),getattr(self,x).min(),np.nan,getattr(self,x).max(),getattr(self,x).max()],[T2(self.pow_2018),T2(self.pow_best),np.nan,T2(self.pow_2018),T2(self.pow_best)],lw=lw,label=\"2018 flight (%0.1f) - most optimistic case (%0.1f)\"%(self.pow_2018,self.pow_best),c=\"r\",alpha=0.5)\n",
    "        self.T2=T2\n",
    "        self.ax4b = ax4b\n",
    "        ax4.legend(loc=\"upper right\", fontsize=8,title=\"Left: Extend. source F, Right: Point source power\" )\n",
    "        ax4.set_ylabel(r\"Log(erg/cm$^2$/s/asec$^2$)\")\n",
    "        ax4b.set_ylabel(r\" Log(erg/s)\")\n",
    "\n",
    "        axes[-1].set_xlabel(x)\n",
    "        ax1.tick_params(labelright=True,right=True)\n",
    "        ax2.tick_params(labelright=True,right=True)\n",
    "        ax3.tick_params(labelright=True,right=True)\n",
    "        fig.tight_layout(h_pad=0.01)\n",
    "        return fig \n",
    "\n",
    "    \n",
    "    def compute_optimal_threshold(self,flux = 0.1,dark_cic_sky_noise=None,plot_=False,title='',i=0,axes=None,size= (int(1e3),int(1e3)),size_bin=25, threshold=-1000):\n",
    "        \"\"\" \n",
    "        Create a ADU value histogram and defin the threshold so that it gives the optimal SNR based on RN, smearing, noise, flux, gain\n",
    "        Function is pretty slow so output of this function has been saved and can then directly be used with interpolation (see function interpolate_optimal_threshold)\n",
    "        \"\"\"\n",
    "        #self.Signal_el if np.isscalar(self.Signal_el) else 0.3\n",
    "        EM_gain = self.EM_gain if np.isscalar(self.EM_gain) else self.EM_gain[i]#1000\n",
    "        RN = self.RN if np.isscalar(self.RN) else self.RN[i]#80\n",
    "        CIC_noise = self.CIC_noise if np.isscalar(self.CIC_noise) else self.CIC_noise[i]\n",
    "        dark_noise = self.Dark_current_noise if np.isscalar(self.Dark_current_noise) else self.Dark_current_noise[i]\n",
    "         \n",
    "        try:\n",
    "            Sky_noise = self.Sky_noise_pre_thresholding if np.isscalar(self.Sky_noise_pre_thresholding) else self.Sky_noise_pre_thresholding[i]\n",
    "        except AttributeError:\n",
    "            raise AttributeError('You must use counting_mode=True to use compute_optimal_threshold method.')\n",
    "\n",
    "        im = np.random.poisson(flux, size=size)\n",
    "        values,bins = np.histogram(im,bins=[-0.5,0.5,1.5,2.5])\n",
    "        ConversionGain=1#/4.5\n",
    "        imaADU = np.random.gamma(im, EM_gain) *ConversionGain\n",
    "        bins = np.arange(np.min(imaADU)-5*RN*ConversionGain,np.max(imaADU)+5*RN*ConversionGain,25)\n",
    "        # bins = np.linspace(-500,10000,400)\n",
    "        #imaADU = (np.random.gamma(im, EM_gain) + np.random.normal(0, RN, size=size))*ConversionGain\n",
    "        if plot_:\n",
    "            if axes is None:\n",
    "                fig, (ax1, ax2) = plt.subplots(2,1,sharex=True,figsize=(12, 7))#,figsize=(9,5))\n",
    "            else:\n",
    "                fig=0\n",
    "                ax1, ax2 = axes\n",
    "                ax1.clear()\n",
    "                ax2.clear()\n",
    "            val0,_,l0 = ax1.hist(imaADU[im==0],bins=bins,alpha=0.5,log=True,histtype='step',lw=0.5,color='k',label='Before ampl & smearing')\n",
    "            val1,_,l1 = ax1.hist(imaADU[im==1],bins=bins,alpha=0.5,log=True,histtype='step',lw=0.5,color='k')\n",
    "            val2,_,l2 = ax1.hist(imaADU[im==2],bins=bins,alpha=0.5,log=True,histtype='step',lw=0.5,color='k')\n",
    "\n",
    "\n",
    "        if self.smearing > 0:\n",
    "            # print(SmearExpDecrement)\n",
    "            smearing_kernels = variable_smearing_kernels(\n",
    "                imaADU, self.smearing, SmearExpDecrement=5e4)\n",
    "            offsets = np.arange(6)\n",
    "            A = dia_matrix(\n",
    "                (smearing_kernels.reshape((6, -1)), offsets),\n",
    "                shape=(imaADU.size, imaADU.size))\n",
    "\n",
    "            imaADU = A.dot(imaADU.ravel()).reshape(imaADU.shape)\n",
    "        imaADU += np.random.normal(0, RN, size=size)*ConversionGain\n",
    "        if plot_:\n",
    "            val0,_,l0 = ax1.hist(imaADU[im==0],bins=bins,alpha=0.5,label='0',log=True)\n",
    "            val1,_,l1 = ax1.hist(imaADU[im==1],bins=bins,alpha=0.5,label='1',log=True)\n",
    "            val2,_,l2 = ax1.hist(imaADU[im==2],bins=bins,alpha=0.5,label='2',log=True)\n",
    "            ax1.hist(imaADU.flatten(),bins=bins,label='Total histogram',log=True,histtype='step',lw=1,color='k')\n",
    "        else:\n",
    "            val0,_ = np.histogram(imaADU[im==0],bins=bins)#,alpha=0.5,label='0',log=True)\n",
    "            val1,_ = np.histogram(imaADU[im==1],bins=bins)#,alpha=0.5,label='1',log=True)\n",
    "            val2,_ = np.histogram(imaADU[im==2],bins=bins)#,alpha=0.5,label='2',log=True)\n",
    "\n",
    "        b = (bins[:-1]+bins[1:])/2\n",
    "        rn_frac = np.array([np.sum(val0[b>bi]) for bi in b])/np.sum(val0) \n",
    "        rn_noise = (RN/(EM_gain * ConversionGain)) * rn_frac #/(EM_gain*ConversionGain)#/(EM_gain*ConversionGain)\n",
    "        # rn_noise = RN * np.array([np.sum(val0[b>bi]) for bi in b])/np.sum(val0) #/(EM_gain*ConversionGain)#/(EM_gain*ConversionGain)\n",
    "        signal12 = flux * np.array([np.sum(val1[b>bi])+np.sum(val2[b>bi]) for bi in b])/(np.sum(val1)+np.sum(val2))\n",
    "        signal1 = flux * np.array([np.sum(val1[b>bi]) for bi in b])/np.sum(val1)\n",
    "\n",
    "        pc = np.ones(len(b))# \n",
    "              # ([np.sum(val1[b>bi])for bi in b]/(np.array([np.sum(val1[b>bi])for bi in b])+np.array([np.sum(val0[b>bi]) for bi in b])))\n",
    "        pc =  ([np.sum(val1[b>bi])for bi in b]/(np.array([np.sum(val1[b>bi])for bi in b])+np.array([np.sum(val0[b>bi]) for bi in b])))\n",
    "\n",
    "        if dark_cic_sky_noise is None:\n",
    "            noise = CIC_noise**2+dark_noise**2+Sky_noise**2\n",
    "        else:\n",
    "            noise = dark_cic_sky_noise\n",
    "        # print('noises = ',noise)\n",
    "        SNR1 = pc*signal1/np.sqrt(signal1+noise)#+np.array(rn_noise)**2\n",
    "        SNR12 = pc*signal12/ np.sqrt(signal12+noise+np.array(rn_noise)**2)\n",
    "        SNR_analogic = flux/np.sqrt(2*flux+2*noise+(RN/(EM_gain * ConversionGain))**2)\n",
    "        # print('SNR_analogic = ',SNR_analogic)\n",
    "        threshold_55 = 5.5*RN*ConversionGain\n",
    "        id_55 =  np.argmin(abs(threshold_55 - b))\n",
    "        if threshold<-5:\n",
    "            id_t = np.nanargmax(SNR1)\n",
    "            threshold = b[id_t]\n",
    "        else:\n",
    "            threshold *= RN*ConversionGain\n",
    "            id_t = np.argmin(abs(threshold - b))\n",
    "        # print(threshold)\n",
    "        fraction_signal = np.sum(val1[id_t:])/np.sum(val1)\n",
    "        fraction_rn = np.sum(val0[id_t:])/np.sum(val0)\n",
    "        lw=3\n",
    "        if plot_:\n",
    "            ax2.plot(b,signal1/flux,label='Signal(Signal>T):  %0.1f%% ➛ %0.1f%%'%(100*signal1[id_55]/flux,100*signal1[id_t]/flux),lw=lw)\n",
    "            ax2.plot(b,rn_frac,label='RN(RN>T):  %0.2f%% ➛ %0.2f%%'%(100*rn_frac[id_55],100*rn_frac[id_t]),lw=lw)\n",
    "            # ax2.plot(b,np.array(rn_noise)**2,label='(RN(RN>T)/EM_gain)**2',lw=lw)\n",
    "            ax2.plot(b,pc,label='Fraction(T) of true positive: %0.1f%% ➛ %0.1f%%'%(100*pc[id_55],100*pc[id_t]),lw=lw)\n",
    "            #ax2.plot(b,SNR1/pc,label='SNR without fraction')\n",
    "\n",
    "            ax2.plot(b,SNR1/SNR1.max(),label='SNR1: %0.2f%% ➛ %0.2f%%'%(SNR1[id_55],SNR1[id_t]),lw=lw) #'%(100*np.sum(val0[id_t:])/np.sum(val0),100*np.sum(val1[id_t:])/np.sum(val1)),lw=lw)\n",
    "            # ax2.plot(b,SNR12,':',label='SNR12, [N1+N2]/[N0] = %0.2f, frac(N1+N2)=%i%%'%((val1[np.nanargmax(SNR12)]+val2[np.nanargmax(SNR12)])/val0[np.nanargmax(SNR12)],100*np.sum(val1[np.nanargmax(SNR12):]+val2[np.nanargmax(SNR12):])/(np.sum(val1)+np.sum(val2))),lw=lw)\n",
    "            ax2.plot(b,SNR1/SNR_analogic,label='SNR1 PC / SNR analogic: %0.2f ➛ %0.2f'%(SNR1[id_55]/SNR_analogic,SNR1[id_t]/SNR_analogic),lw=lw)\n",
    "            # ax2.plot(b,SNR12/SNR_analogic,':',label='SNR12 PC / SNR analogic',lw=lw)\n",
    "            # ax2.set_yscale('log')\n",
    "            ax2.set_ylim(ymin=1e-5)\n",
    "            \n",
    "            # ax2.plot(b,SNR1,label='[N1]/[N0] = %0.2f, frac(N1)=%i%%'%(val1[id_t]/val0[id_t],100*np.sum(val1[id_t:])/np.sum(val1)))\n",
    "            # ax2.plot(b,SNR12,label='[N1+N2]/[N0] = %0.2f, frac(N1+N2)=%i%%'%((val1[np.nanargmax(SNR12)]+val2[np.nanargmax(SNR12)])/val0[np.nanargmax(SNR12)],100*np.sum(val1[np.nanargmax(SNR12):]+val2[np.nanargmax(SNR12):])/(np.sum(val1)+np.sum(val2))))\n",
    "\n",
    "            L = ax1.legend(fontsize=10)\n",
    "            ax2.legend(title = \"T = 5.5σ ➛ %0.1fσ \"%(threshold/(RN*ConversionGain)), fontsize=10)\n",
    "            ax2.set_xlabel('ADU')\n",
    "            ax1.set_ylabel('#')\n",
    "            ax2.set_ylabel('SNR')\n",
    "            L.get_texts()[1].set_text('0 e- : %i%%, faction kept: %0.2f%%'%(100*values[0]/(size[0]*size[1]),100*np.sum(val0[id_t:])/np.sum(val0)))\n",
    "            L.get_texts()[2].set_text('1 e- : %i%%, faction kept: %0.2f%%'%(100*values[1]/(size[0]*size[1]),100*np.sum(val1[id_t:])/np.sum(val1)))\n",
    "            L.get_texts()[3].set_text('2 e- : %i%%, faction kept: %0.2f%%'%(100*values[2]/(size[0]*size[1]),100*np.sum(val2[id_t:])/np.sum(val2)))\n",
    "            ax1.plot([threshold,threshold],[0,np.max(val0)],':',c='k')\n",
    "            ax2.plot([threshold,threshold],[0,1],':',c='k')\n",
    "            ax1.plot([threshold_55,threshold_55],[0,np.max(val0)],'-.',c='k')\n",
    "            ax2.plot([threshold_55,threshold_55],[0,1],'-.',c='k')\n",
    "\n",
    "            ax1.set_title(title+'Gain = %i, RN = %i, flux = %0.2f, smearing=%0.1f, Threshold = %i = %0.2f$\\sigma$'%(EM_gain,RN,flux,self.smearing, threshold,threshold/(RN*ConversionGain)))\n",
    "            ax1.set_xlim(xmin=bins.min(),xmax=7000)#bins.max())\n",
    "            if axes is None:\n",
    "                fig.tight_layout()\n",
    "            return fig\n",
    "        return threshold/(RN*ConversionGain), fraction_signal, fraction_rn, np.nanmax(SNR1/SNR_analogic)\n",
    " \n",
    "\n",
    "\n",
    "    def interpolate_optimal_threshold(self,flux = 0.1,dark_cic_sky_noise=None,plot_=False,title='',i=0):\n",
    "        \"\"\"\n",
    "        Return the threshold optimizing the SNR\n",
    "        \"\"\"\n",
    "        #self.Signal_el if np.isscalar(self.Signal_el) else 0.3\n",
    "        EM_gain = self.EM_gain #if np.isscalar(self.EM_gain) else self.EM_gain[i]\n",
    "        RN= self.RN #if np.isscalar(self.RN) else self.RN[i]#80\n",
    "        CIC_noise = self.CIC_noise #if np.isscalar(self.CIC_noise) else self.CIC_noise[i]\n",
    "        dark_noise = self.Dark_current_noise #if np.isscalar(self.Dark_current_noise) else self.Dark_current_noise[i]\n",
    "         \n",
    "        try:\n",
    "            Sky_noise = self.Sky_noise_pre_thresholding #if np.isscalar(self.Sky_noise_pre_thresholding) else self.Sky_noise_pre_thresholding[i]\n",
    "        except AttributeError:\n",
    "            raise AttributeError('You must use counting_mode=True to use compute_optimal_threshold method.')\n",
    "\n",
    "        noise_value = CIC_noise**2+dark_noise**2+Sky_noise**2\n",
    "        \n",
    "        gains=np.linspace(800,2500,n)#self.len_xaxis)\n",
    "        rons=np.linspace(30,120,n)#self.len_xaxis)\n",
    "        fluxes=np.linspace(0.01,0.7,n)#self.len_xaxis)\n",
    "        smearings=np.linspace(0,2,n)#self.len_xaxis)\n",
    "        noise=np.linspace(0.002,0.05,n)#self.len_xaxis)\n",
    "        if (n==6)|(n==10):\n",
    "            coords = (gains, rons, fluxes, smearings)\n",
    "            point = (EM_gain, RN, flux, self.smearing)            \n",
    "        elif n==5:\n",
    "            coords = (gains, rons, fluxes, smearings,noise)\n",
    "            point = (EM_gain, RN, flux, self.smearing,noise_value)\n",
    "        else:\n",
    "            print(n,EM_gain, RN, flux, self.smearing,noise_value)\n",
    "            \n",
    "        if ~np.isscalar(noise_value) |  ~np.isscalar(self.smearing) | ~np.isscalar(EM_gain) | ~np.isscalar(RN):\n",
    "            point = np.repeat(np.zeros((4,1)), self.len_xaxis, axis=1).T\n",
    "            point[:,0] =  self.EM_gain\n",
    "            point[:,1] = self.RN\n",
    "            point[:,2] = flux\n",
    "            point[:,3] = self.smearing\n",
    "        fraction_rn =interpn(coords, table_fraction_rn, point,bounds_error=False,fill_value=None)\n",
    "        fraction_signal =interpn(coords, table_fraction_flux, point,bounds_error=False,fill_value=None)\n",
    "        threshold = interpn(coords, table_threshold, point,bounds_error=False,fill_value=None)\n",
    "        snr_ratio = interpn(coords, table_snr, point,bounds_error=False,fill_value=None)\n",
    "\n",
    "        if type(self.smearing)==float:\n",
    "            if self.smearing == 0:\n",
    "                a = Table.read(\"fraction_flux.csv\")\n",
    "                threshold = 5.5\n",
    "                fraction_signal = np.interp(self.EM_gain/self.RN,a[\"G/RN\"],a[\"fractionflux\"])\n",
    "            # fraction_rn = f(flux=0.1,EM_gain=self.EM_gain, RN=self.RN)\n",
    "            # fraction_signal = f2(flux=0.1,EM_gain=self.EM_gain, RN=self.RN)\n",
    "            # snr_ratio = f3(flux=0.1,EM_gain=self.EM_gain, RN=self.RN)\n",
    "\n",
    "        return threshold, fraction_signal, fraction_rn, snr_ratio#np.nanmax(SNR1/SNR_analogic)\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "    def SimulateFIREBallemCCDImage(self, conv_gain=0.53,  Bias=\"Auto\",  p_sCIC=0,  SmearExpDecrement=50000,  source=\"Slit\", size=[100, 100], OSregions=[0, 100], name=\"Auto\", spectra=\"-\", cube=\"-\", n_registers=604, save=False, field=\"targets_F2.csv\",QElambda=True,atmlambda=True,fraction_lya=0.05):\n",
    "        # self.EM_gain=1500; Bias=0; self.RN=80; self.CIC_charge=1; p_sCIC=0; self.Dard_current=1/3600; self.smearing=1; SmearExpDecrement=50000; self.exposure_time=50; flux=1; self.Sky=4; source=\"Spectra m=17\"; Rx=8; Ry=8;  size=[100, 100]; OSregions=[0, 120]; name=\"Auto\"; spectra=\"Spectra m=17\"; cube=\"-\"; n_registers=604; save=False;self.readout_time=5;stack=100;self.QE=0.5\n",
    "        from astropy.modeling.functional_models import Gaussian2D, Gaussian1D\n",
    "        from scipy.sparse import dia_matrix\n",
    "        from scipy.interpolate import interp1d\n",
    "        for key in list(instruments[\"Charact.\"]) + [\"Signal_el\",\"N_images_true\",\"Dark_current_f\",\"sky\"]:\n",
    "            if hasattr(self,key ):\n",
    "                if (type(getattr(self,key)) != float) & (type(getattr(self,key)) != int) &  (type(getattr(self,key)) != np.float64):\n",
    "                    setattr(self, key,getattr(self,key)[self.i])\n",
    "                    # print(getattr(self,key))\n",
    "                    # print(key, self.i)\n",
    "                    # print(getattr(self,key)[self.i])\n",
    "                    # a = getattr(self,key)[self.i]\n",
    "                    # print(a,self.setattr(key),)\n",
    "\n",
    "\n",
    "\n",
    "        OS1, OS2 = OSregions\n",
    "        # ConversionGain=1\n",
    "        ConversionGain = conv_gain\n",
    "        Bias=0\n",
    "        image = np.zeros((size[1], size[0]), dtype=\"float64\")\n",
    "        image_stack = np.zeros((size[1], size[0]), dtype=\"float64\")\n",
    "\n",
    "        # self.Dard_current & flux\n",
    "        source_im = 0 * image[:, OSregions[0] : OSregions[1]]\n",
    "        source_im_wo_atm = 0 * image[:, OSregions[0] : OSregions[1]]\n",
    "        lx, ly = source_im.shape\n",
    "        y = np.linspace(0, lx - 1, lx)\n",
    "        x = np.linspace(0, ly - 1, ly)\n",
    "        x, y = np.meshgrid(x, y)\n",
    "\n",
    "        # Source definition. For now the flux is not normalized at all, need to fix this\n",
    "        # Cubes still needs to be implememted, link to detector model or putting it here?\n",
    "        # if os.path.isfile(cube):\n",
    "        # throughput = self.Throughput.value#0.13*0.9\n",
    "        # atm = self.Atmosphere.value#0.45\n",
    "        # area = self.Collecting_area.value/100/100#7854\n",
    "        # dispersion = 1/self.dispersion.value#46.6/10\n",
    "        # wavelength=self.wavelength.value/10 #2000\n",
    "        stack = int(self.N_images_true)\n",
    "        flux = (self.Signal_el /self.exposure_time)\n",
    "        Rx = self.PSF_RMS_det/self.pixel_scale\n",
    "        PSF_x = np.sqrt((np.min([self.PSF_source/self.pixel_scale,self.Slitlength/self.pixel_scale]))**2 + (Rx)**2)\n",
    "        PSF_λ = np.sqrt(self.PSF_lambda_pix**2 + (self.Line_width/self.dispersion)**2)\n",
    "                        #%%\n",
    "\n",
    "        if (\"Spectra\" in source) | (\"Salvato\" in source) | (\"COSMOS\" in source):\n",
    "            if \"baseline\" in source.lower():\n",
    "                # print(PSF_x,PSF_λ)\n",
    "                # print(self.PSF_source,self.pixel_scale,self.PSF_RMS_det,self.pixel_scale)\n",
    "                with_line = flux* Gaussian1D.evaluate(np.arange(size[0]),  1,  size[0]/2, PSF_λ)#/ Gaussian1D.evaluate(np.arange(size[0]),  1,  size[0]/2, PSF_λ).sum()\n",
    "                # source_im[50:55,:] += elec_pix #Gaussian2D.evaluate(x, y, flux, ly / 2, lx / 2, 100 * Ry, Rx, 0)\n",
    "                profile =  np.outer(with_line,Gaussian1D.evaluate(np.arange(size[1]),  1,  50, PSF_x) )#/Gaussian1D.evaluate(np.arange(size[1]),  1,  50, PSF_x).sum()\n",
    "                source_im = source_im.T\n",
    "                source_im[:,:] += profile\n",
    "                source_im = source_im.T \n",
    "                length = self.Slitlength/2/self.pixel_scale\n",
    "                #TODO take into account the PSF: += Gaussian1D.evaluate(np.arange(size[1]),  1,  50, PSF_x) with special.erf\n",
    "                source_im[50-int(length):50+int(length),:] += self.sky/self.exposure_time  \n",
    "                \n",
    "            # source_im[50:55,:] += elec_pix #Gaussian2D.evaluate(x, y, flux, ly / 2, lx / 2, 100 * Ry, Rx, 0)\n",
    "\n",
    "\n",
    "\n",
    "            elif \"mNUV=\" in source:\n",
    "                #%%\n",
    "                mag=float(source.split(\"mNUV=\")[-1])\n",
    "                factor_lya = fraction_lya\n",
    "                flux = 10**(-(mag-20.08)/2.5)*2.06*1E-16/((6.62E-34*300000000/(self.wavelength*0.0000000001)/0.0000001))\n",
    "                elec_pix = flux * self.Throughput * self.Atmosphere * self.QE * self.Collecting_area*100*100 *self.dispersion# should not be multiplied by self.exposure_time time here\n",
    "                with_line = elec_pix*(1-factor_lya) + factor_lya * (3700/1)*elec_pix* Gaussian1D.evaluate(np.arange(size[0]),  1,  size[0]/2,PSF_λ)/ Gaussian1D.evaluate(np.arange(size[0]),  1,  size[0]/2, PSF_λ).sum()\n",
    "                # source_im[50:55,:] += elec_pix #Gaussian2D.evaluate(x, y, flux, ly / 2, lx / 2, 100 * Ry, Rx, 0)\n",
    "                profile =  np.outer(with_line,Gaussian1D.evaluate(np.arange(size[1]),  1,  50, PSF_x) /Gaussian1D.evaluate(np.arange(size[1]),  1,  50, Rx).sum())\n",
    "                source_im = source_im.T\n",
    "                source_im[:,:] += profile\n",
    "                # source_im = source_im.T\n",
    "                # a = Table(data=([np.linspace(1500,2500,nsize2),np.zeros(nsize2)]),names=(\"WAVELENGTH\",\"e_pix_sec\"))\n",
    "                # a[\"e_pix_sec\"] = elec_pix*(1-factor_lya) + factor_lya * (3700/1)*elec_pix* Gaussian1D.evaluate(a[\"WAVELENGTH\"],  1,  line[\"wave\"], 8) \n",
    "                # f = interp1d(a[\"WAVELENGTH\"],a[\"e_pix_sec\"])\n",
    "                # profile =   Gaussian1D.evaluate(np.arange(nsize),  1,  nsize/2, Rx) /Gaussian1D.evaluate(np.arange(nsize),  1,  nsize/2, Rx).sum()\n",
    "                # subim = np.zeros((nsize2,nsize))\n",
    "                # wavelengths = np.linspace(2060-yi*dispersion,2060+(1000-yi)*dispersion,nsize2)\n",
    "                # source_im[int(xi-nsize/2):int(xi+nsize/2), OSregions[0] : OSregions[1]] +=  (subim+profile).T*f(wavelengths) * atm_trans(wavelengths) * self.QE(wavelengths)\n",
    "                # source_im_wo_atm[int(xi-nsize/2):int(xi+nsize/2), OSregions[0] : OSregions[1]] +=  (subim+profile).T*f(wavelengths) #* atm_trans(wavelengths)\n",
    "                \n",
    "            else:\n",
    "                # for file in glob.glob(\"/Users/Vincent/Downloads/FOS_spectra/FOS_spectra_for_FB/CIV/*.fits\"):\n",
    "                if \"_\" not in source:\n",
    "                    try:\n",
    "                        a = Table.read(\"Spectra/h_%sfos_spc.fits\"%(source.split(\" \")[1]))\n",
    "                        flux_name,wave_name =\"FLUX\", \"WAVELENGTH\"\n",
    "                    except FileNotFoundError: \n",
    "                        a = Table.read(\"/Users/Vincent/Github/notebooks/Spectra/h_%sfos_spc.fits\"%(source.split(\" \")[-1]))\n",
    "                        # slits = Table.read(\"/Users/Vincent/Github/FireBallPipe/Calibration/Targets/2022/\" + field).to_pandas()\n",
    "                        # trans = Table.read(\"/Users/Vincent/Github/FIREBall_IMO/Python Package/FireBallIMO-1.0/FireBallIMO/transmission_pix_resolution.csv\")\n",
    "                        # self.QE = Table.read(\"interpolate/QE_2022.csv\")\n",
    "                elif \"COSMOS\" in source:\n",
    "                    a = Table.read(\"Spectra/GAL_COSMOS_SED/%s.sed\"%(source.split(\" \")[1]),format=\"ascii\")\n",
    "                    flux_name,wave_name =\"col1\", \"col2\"\n",
    "                elif \"Salvato\" in source:\n",
    "                    a = Table.read(\"Spectra/Salvato/%s.sed\"%(source.split(\" \")[1]),format=\"ascii\")\n",
    "                    flux_name,wave_name =\"col1\", \"col2\"\n",
    "                slits = None#Table.read(\"Targets/2022/\" + field).to_pandas()\n",
    "                trans = Table.read(\"interpolate/transmission_pix_resolution.csv\")\n",
    "                self.QE = Table.read(\"interpolate/QE_2022.csv\")\n",
    "                self.QE = interp1d(self.QE[\"wave\"]*10,self.QE[\"QE_corr\"])#\n",
    "                print(trans[\"col2\"],trans)\n",
    "                # trans[\"trans_conv\"] = np.convolve(trans[\"col2\"],np.ones(int(self.PSF_lambda_pix))/int(self.PSF_lambda_pix),mode=\"same\")\n",
    "                trans[\"trans_conv\"] = np.convolve(trans[\"col2\"],np.ones(int(5))/int(5),mode=\"same\")\n",
    "                trans = trans[:-5]\n",
    "                atm_trans =  interp1d([1500,2500]+list(trans[\"col1\"]*10),[0,0] + list(trans[\"trans_conv\"]))#\n",
    "\n",
    "                a[\"photons\"] = a[flux_name]/9.93E-12   \n",
    "                a[\"e_pix_sec\"]  = a[\"photons\"] * self.Throughput * self.Atmosphere  * self.Collecting_area*100*100 *self.dispersion\n",
    "                nsize,nsize2 = 100,500\n",
    "                source_im=np.zeros((nsize,nsize2))\n",
    "                source_im_wo_atm=np.zeros((nsize2,nsize))\n",
    "                mask = (a[wave_name]>1960) & (a[wave_name]<2280)\n",
    "                lmax = a[wave_name][mask][np.argmax( a[\"e_pix_sec\"][mask])]\n",
    "                # plt.plot( a[\"WAVELENGTH\"],a[\"e_pix_sec\"])\n",
    "                # plt.plot( a[\"WAVELENGTH\"][mask],a[\"e_pix_sec\"][mask])\n",
    "                f = interp1d(a[\"WAVELENGTH\"],a[\"e_pix_sec\"])#\n",
    "                profile =   Gaussian1D.evaluate(np.arange(nsize),  1,  nsize/2, PSF_x) /Gaussian1D.evaluate(np.arange(nsize),  1,  nsize/2, PSF_x).sum()\n",
    "                subim = np.zeros((nsize2,nsize))\n",
    "                wavelengths = np.linspace(lmax-nsize2/2*self.dispersion,lmax+nsize2/2*self.dispersion,nsize2)\n",
    "\n",
    "                if 1==0:\n",
    "                    # source_im=np.zeros((100,100))\n",
    "                    # # plt.plot(a[\"WAVELENGTH\"][mask],a[\"e_pix_exp\"][mask])\n",
    "                    # profile =   Gaussian1D.evaluate(np.arange(100),  1,  50, Rx) /Gaussian1D.evaluate(np.arange(100),  1,  50, Rx).sum()\n",
    "                    # i = np.argmin(abs(a[\"WAVELENGTH\"]-1960))\n",
    "                    # source_im[:,:] +=   profile\n",
    "                    # source_im = source_im.T*a[\"e_pix_sec\"][i:i+100]                    \n",
    "                    fig,(ax0,ax1,ax2) = plt.subplots(3,1)\n",
    "                    ax0.fill_between(wavelengths, profile.max()*f(wavelengths),profile.max()* f(wavelengths) * atm_trans(wavelengths),label=\"Atmosphere impact\",alpha=0.3)\n",
    "                    ax0.fill_between(wavelengths, profile.max()*f(wavelengths)* atm_trans(wavelengths)*self.QE(wavelengths),profile.max()* f(wavelengths) * atm_trans(wavelengths),label=\"self.QE impact\",alpha=0.3)\n",
    "                    ax1.plot(wavelengths,f(wavelengths)/f(wavelengths).ptp(),label=\"Spectra\")\n",
    "                    ax1.plot(wavelengths, f(wavelengths)* atm_trans(wavelengths)/(f(wavelengths)* atm_trans(wavelengths)).ptp(),label=\"Spectra * Atm\")\n",
    "                    ax1.plot(wavelengths, f(wavelengths)* atm_trans(wavelengths)*self.QE(wavelengths)/( f(wavelengths)* atm_trans(wavelengths)*self.QE(wavelengths)).ptp(),label=\"Spectra * Atm * self.QE\")\n",
    "                    ax2.plot(wavelengths,atm_trans(wavelengths) ,label=\"Atmosphere\")\n",
    "                    ax2.plot(wavelengths,self.QE(wavelengths) ,label=\"self.QE\")\n",
    "                    ax0.legend()\n",
    "                    ax1.legend()\n",
    "                    ax2.legend()\n",
    "                    ax0.set_ylabel(\"e/pix/sec\")\n",
    "                    ax1.set_ylabel(\"Moself.RNalized prof\")\n",
    "                    ax2.set_ylabel(\"%\")\n",
    "                    ax2.set_xlabel(\"wavelength\")\n",
    "                    ax0.set_title(source.split(\" \")[-1])\n",
    "                    fig.savefig(\"/Users/Vincent/Github/notebooks/Spectra/h_%sfos_spc.png\"%(source.split(\" \")[-1]))\n",
    "                    plt.show()\n",
    "                self.QE = self.QE(wavelengths) if QElambda else self.QE(lmax) \n",
    "                atm_trans = atm_trans(wavelengths) if atmlambda else atm_trans(lmax) \n",
    "                source_im[:,:] +=  (subim+profile).T*f(wavelengths) * atm_trans * self.QE\n",
    "                # source_im_wo_atm[:,:] +=  (subim+profile).T*f(wavelengths) #* atm_trans(wavelengths)\n",
    "        source_im = self.Dark_current_f  + self.extra_background * int(self.exposure_time)/3600 +  source_im  * int(self.exposure_time)\n",
    "        source_im_wo_atm = self.Dark_current_f + self.extra_background * int(self.exposure_time)/3600 +  source_im_wo_atm * int(self.exposure_time)\n",
    "        y_pix=1000\n",
    "        # print(len(source_im),source_im.shape)\n",
    "        self.long = True\n",
    "        if (self.readout_time/self.exposure_time > 0.2) & (self.long):\n",
    "            # print(source_im)\n",
    "            cube = np.array([(self.readout_time/self.exposure_time/y_pix)*np.vstack((np.zeros((i,len(source_im))),source_im[::-1,:][:-i,:]))[::-1,:] for i in np.arange(1,len(source_im))],dtype=float)\n",
    "            source_im = source_im+np.sum(cube,axis=0)\n",
    "        if self.cosmic_ray_loss_per_sec is None:\n",
    "            self.cosmic_ray_loss_per_sec = np.minimum(0.005*(self.exposure_time+self.readout_time/2),1)#+self.readout_time/2\n",
    "        # stack = np.max([int(stack * (1-self.cosmic_ray_loss_per_sec)),1])\n",
    "        stack = int(self.N_images_true)\n",
    "        cube_stack = -np.ones((stack,size[1], size[0]), dtype=\"int32\")\n",
    "\n",
    "        # print(self.cosmic_ray_loss_per_sec)\n",
    "        n_smearing=6\n",
    "        # image[:, OSregions[0] : OSregions[1]] += source_im\n",
    "        # print(image[:, OSregions[0] : OSregions[1]].shape,source_im.shape)\n",
    "        image[:, OSregions[0] : OSregions[1]] += np.random.gamma( np.random.poisson(source_im) + np.array(np.random.rand(size[1], OSregions[1]-OSregions[0])<self.CIC_charge,dtype=int) , self.EM_gain)\n",
    "        # take into acount CR losses\n",
    "        #18%\n",
    "        # image_stack[:, OSregions[0] : OSregions[1]] = np.nanmean([np.where(np.random.rand(size[1], OSregions[1]-OSregions[0]) < self.cosmic_ray_loss_per_sec/n_smearing,np.nan,1) * (np.random.gamma(np.random.poisson(source_im)  + np.array(np.random.rand(size[1], OSregions[1]-OSregions[0])<self.CIC_charge,dtype=int) , self.EM_gain)) for i in range(int(stack))],axis=0)\n",
    "        image_stack[:, OSregions[0] : OSregions[1]] = np.mean([(np.random.gamma(np.random.poisson(source_im)  + np.array(np.random.rand(size[1], OSregions[1]-OSregions[0])<self.CIC_charge,dtype=int) , self.EM_gain)) for i in range(int(stack))],axis=0)\n",
    "        \n",
    "        # a = (np.where(np.random.rand(int(stack), size[1],OSregions[1]-OSregions[0]) < self.cosmic_ray_loss_per_sec/n_smearing,np.nan,1) * np.array([ (np.random.gamma(np.random.poisson(source_im)  + np.array(np.random.rand( OSregions[1]-OSregions[0],size[1]).T<self.CIC_charge,dtype=int) , self.EM_gain))  for i in range(int(stack))]))\n",
    "        # Addition of the phyical image on the 2 overscan regions\n",
    "        #image += source_im2\n",
    "        if p_sCIC>0:\n",
    "            image +=  np.random.gamma( np.array(np.random.rand(size[1], size[0])<p_sCIC,dtype=int) , np.random.randint(1, n_registers, size=image.shape))\n",
    "            #30%\n",
    "            image_stack += np.random.gamma( np.array(np.random.rand(size[1], size[0])<int(stack)*p_sCIC,dtype=int) , np.random.randint(1, n_registers, size=image.shape))\n",
    "        if self.counting_mode:\n",
    "            a = np.array([ (np.random.gamma(np.random.poisson(source_im)  + np.array(np.random.rand( OSregions[1]-OSregions[0],size[1]).T<self.CIC_charge,dtype=\"int32\") , self.EM_gain))  for i in range(int(stack))])\n",
    "            cube_stack[:,:, OSregions[0] : OSregions[1]] = a\n",
    "            cube_stack += np.random.gamma( np.array(np.random.rand(int(stack),size[1], size[0])<int(stack)*p_sCIC,dtype=int) , np.random.randint(1, n_registers, size=image.shape)).astype(\"int32\")\n",
    "            # print(cube_stack.shape)\n",
    "        #         # addition of pCIC (stil need to add sCIC before EM registers)\n",
    "        #         prob_pCIC = np.random.rand(size[1], size[0])  # Draw a number prob in [0,1]\n",
    "        #         image[prob_pCIC < self.CIC_charge] += 1\n",
    "        #         source_im2_stack[prob_pCIC < p_pCIC*stack] += 1\n",
    "\n",
    "        #         # EM amp (of source + self.Dard_current + pCIC)\n",
    "        #         id_nnul = image != 0\n",
    "        #         image[id_nnul] = np.random.gamma(image[id_nnul], self.EM_gain)\n",
    "                # Addition of sCIC inside EM registers (ie partially amplified)\n",
    "        #         prob_sCIC = np.random.rand(size[1], size[0])  # Draw a number prob in [0,1]\n",
    "        #         id_scic = prob_sCIC < p_sCIC  # sCIC positions\n",
    "        #         # partial amplification of sCIC\n",
    "        #         register = np.random.randint(1, n_registers, size=id_scic.sum())  # Draw at which stage of the EM register the electoself.RN is created\n",
    "        #         image[id_scic] += np.random.exponential(np.power(self.EM_gain, register / n_registers))\n",
    "            # semaring post EM amp (sgest noise reduction)\n",
    "            #TODO must add self.smearing for cube!\n",
    "        if self.smearing > 0:\n",
    "            # self.smearing dependant on flux\n",
    "            #2%\n",
    "            smearing_kernels = variable_smearing_kernels(image, self.smearing, SmearExpDecrement)\n",
    "            offsets = np.arange(n_smearing)\n",
    "            A = dia_matrix((smearing_kernels.reshape((n_smearing, -1)), offsets), shape=(image.size, image.size))\n",
    "\n",
    "            image = A.dot(image.ravel()).reshape(image.shape)\n",
    "            image_stack = A.dot(image_stack.ravel()).reshape(image_stack.shape)\n",
    "        #     if self.readout_time > 0:\n",
    "        #         # self.smearing dependant on flux\n",
    "        #         self.smearing_kernels = variable_smearing.smearing_keself.RNels(image.T, self.readout_time, SmearExpDecrement)#.swapaxes(1,2)\n",
    "        #         offsets = np.arange(n_smearing)\n",
    "        #         A = dia_matrix((self.smearing_kernels.reshape((n_smearing, -1)), offsets), shape=(image.size, image.size))#.swapaxes(0,1)\n",
    "        #         image = A.dot(image.ravel()).reshape(image.shape)#.T\n",
    "        #         image_stack = A.dot(image_stack.ravel()).reshape(image_stack.shape)#.T\n",
    "        type_ = \"int32\"\n",
    "        type_ = \"float64\"\n",
    "        readout = np.random.normal(Bias, self.RN, (size[1], size[0]))\n",
    "        readout_stack = np.random.normal(Bias, self.RN/np.sqrt(int(stack)), (size[1], size[0]))\n",
    "        if self.counting_mode:\n",
    "            readout_cube = np.random.normal(Bias, self.RN, (int(stack),size[1], size[0])).astype(\"int32\")\n",
    "            # print((np.random.rand(source_im.shape[0], source_im.shape[1]) < self.cosmic_ray_loss_per_sec).mean())\n",
    "            #TOKEEP  for cosmic ray masking readout[np.random.rand(source_im.shape[0], source_im.shape[1]) < self.cosmic_ray_loss_per_sec]=np.nan\n",
    "            #print(np.max(((image + readout) * ConversionGain).round()))\n",
    "        #     if np.max(((image + readout) * ConversionGain).round()) > 2 ** 15:\n",
    "        imaADU_wo_RN = (image * ConversionGain).round().astype(type_)\n",
    "        imaADU_RN = (readout * ConversionGain).round().astype(type_)\n",
    "        imaADU = ((image + 1*readout) * ConversionGain).round().astype(type_)\n",
    "        imaADU_stack = ((image_stack + 1*readout_stack) * ConversionGain).round().astype(type_)\n",
    "        if self.counting_mode:\n",
    "            imaADU_cube = ((cube_stack + 1*readout_cube) * ConversionGain).round().astype(\"int32\")\n",
    "        else:\n",
    "            imaADU_cube = imaADU_stack\n",
    "        # print(imaADU_cube.shape)\n",
    "        return imaADU, imaADU_stack, imaADU_cube, source_im, source_im_wo_atm#imaADU_wo_RN, imaADU_RN\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "Observation().SimulateFIREBallemCCDImage(conv_gain=0.53,  Bias=\"Auto\",  p_sCIC=0,  SmearExpDecrement=50000,  source=\"Slit\", size=[100, 100], OSregions=[0, 100], name=\"Auto\", spectra=\"COSMOS ElI4_A_0\", cube=\"-\", n_registers=604, save=False, field=\"targets_F2.csv\",QElambda=True,atmlambda=True,fraction_lya=0.05)\n",
    "# %%\n",
    "\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.2845085897434234e+21"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def convert_ergs2LU(flux_ergs,wave_nm,pixel_size_arcsec):\n",
    "    # pixel_size_arcsec=1\n",
    "    wave =wave_nm * 1e-7 #/ (1+redshift)\n",
    "    Energy = 6.62e-27 * 3e10 / wave\n",
    "    angle =    np.pi / (180 * 3600) / pixel_size_arcsec\n",
    "    LU = flux_ergs/ (Energy  * angle * angle)\n",
    "    # flux_ergs = LU * Energy * angle * angle\n",
    "    return LU\n",
    "convert_ergs2LU(1,wave_nm=200,pixel_size_arcsec=1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3339899525324203e-22"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_LU2ergs(LU,wave_nm,pixel_size_arcsec):\n",
    "    # pixel_size_arcsec=1\n",
    "    wave =wave_nm * 1e-7 #/ (1+redshift)\n",
    "    Energy = 6.62e-27 * 3e10 / wave\n",
    "    angle = pixel_size_arcsec * np.pi / (180 * 3600)\n",
    "    flux_ergs = LU * Energy * angle * angle\n",
    "    return flux_ergs\n",
    "convert_LU2ergs(1,200,pixel_size_arcsec=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (os.path.exists(\"../data/Instruments/%s/Sky_emission_lines.csv\"%(FB.instrument.replace(\" \",\"_\"))) )\n",
    "# print(1)\n",
    "# a = Table.read(\"Sky_emission_lines/spectra.csv\")\n",
    "# fig = plt.figure(figsize=(15,3))\n",
    "# plt.loglog(a[\"# wavelength\"]/10000,a[\"emission_lines\"],\":\",c=\"k\",alpha=0.8,lw=0.2)\n",
    "# plt.ylim(ymin=1e-2)\n",
    "# plt.xlabel(\"Wavelength (microns)\")\n",
    "# plt.ylabel(\"Sky flux in \\n1E-16 erg/[s A cm**2 arcs**2]\")\n",
    "# fig.tight_layout()\n",
    "# plt.show()\n",
    "# # sky model\n",
    "# # sky observing mode\n",
    "# # different modes\n",
    "# # seing"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

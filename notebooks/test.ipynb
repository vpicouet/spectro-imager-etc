{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    def SimulateFIREBallemCCDImage(self, conv_gain=0.53,  Bias=\"Auto\",  p_sCIC=0,  SmearExpDecrement=50000,  source=\"Slit\", size=[100, 100], OSregions=[0, 100], name=\"Auto\", spectra=\"-\", cube=\"-\", n_registers=604, save=False, field=\"targets_F2.csv\",QElambda=True,atmlambda=True,fraction_lya=0.05):\n",
    "        # self.EM_gain=1500; Bias=0; self.RN=80; self.CIC_charge=1; p_sCIC=0; self.Dard_current=1/3600; self.smearing=1; SmearExpDecrement=50000; self.exposure_time=50; flux=1; self.Sky=4; source=\"Spectra m=17\"; Rx=8; Ry=8;  size=[100, 100]; OSregions=[0, 120]; name=\"Auto\"; spectra=\"Spectra m=17\"; cube=\"-\"; n_registers=604; save=False;self.readout_time=5;stack=100;self.QE=0.5\n",
    "        from astropy.modeling.functional_models import Gaussian2D, Gaussian1D\n",
    "        from scipy.sparse import dia_matrix\n",
    "        from scipy.interpolate import interp1d\n",
    "        for key in list(instruments[\"Charact.\"]) + [\"Signal_el\"]:\n",
    "            if hasattr(self,key ):\n",
    "                if (type(getattr(self,key)) != float) & (type(getattr(self,key)) != int) &  (type(getattr(self,key)) != np.float64):\n",
    "                    setattr(self, key,getattr(self,key)[self.i])\n",
    "                    # print(getattr(self,key))\n",
    "                    # print(key, self.i)\n",
    "                    # print(getattr(self,key)[self.i])\n",
    "                    # a = getattr(self,key)[self.i]\n",
    "                    # print(a,self.setattr(key),)\n",
    "\n",
    "\n",
    "\n",
    "        OS1, OS2 = OSregions\n",
    "        # ConversionGain=1\n",
    "        ConversionGain = conv_gain\n",
    "        Bias=0\n",
    "        image = np.zeros((size[1], size[0]), dtype=\"float64\")\n",
    "        image_stack = np.zeros((size[1], size[0]), dtype=\"float64\")\n",
    "\n",
    "        # self.Dard_current & flux\n",
    "        source_im = 0 * image[:, OSregions[0] : OSregions[1]]\n",
    "        source_im_wo_atm = 0 * image[:, OSregions[0] : OSregions[1]]\n",
    "        lx, ly = source_im.shape\n",
    "        y = np.linspace(0, lx - 1, lx)\n",
    "        x = np.linspace(0, ly - 1, ly)\n",
    "        x, y = np.meshgrid(x, y)\n",
    "\n",
    "        # Source definition. For now the flux is not normalized at all, need to fix this\n",
    "        # Cubes still needs to be implememted, link to detector model or putting it here?\n",
    "        # if os.path.isfile(cube):\n",
    "        # throughput = self.Throughput.value#0.13*0.9\n",
    "        # atm = self.Atmosphere.value#0.45\n",
    "        # area = self.Collecting_area.value/100/100#7854\n",
    "        # dispersion = 1/self.dispersion.value#46.6/10\n",
    "        # wavelength=self.wavelength.value/10 #2000\n",
    "        stack = int(self.N_images_true)\n",
    "        flux = (self.Signal_el /self.exposure_time)\n",
    "\n",
    "        PSF_x = np.sqrt((self.PSF_source/self.pixel_scale)**2 + (self.PSF_RMS_det/self.pixel_scale)**2)\n",
    "        PSF_λ = np.sqrt(self.PSF_lambda_pix**2 + (self.Line_width/self.dispersion)**2)\n",
    "                        #%%\n",
    "\n",
    "        if \"Spectra\" in source:\n",
    "            if \"baseline\" in source.lower():\n",
    "                with_line = f* Gaussian1D.evaluate(np.arange(size[0]),  1,  size[0]/2, PSF_λ)/ Gaussian1D.evaluate(np.arange(size[0]),  1,  size[0]/2, PSF_λ).sum()\n",
    "                # source_im[50:55,:] += elec_pix #Gaussian2D.evaluate(x, y, flux, ly / 2, lx / 2, 100 * Ry, Rx, 0)\n",
    "                profile =  np.outer(with_line,Gaussian1D.evaluate(np.arange(size[1]),  1,  50, PSF_x) /Gaussian1D.evaluate(np.arange(size[1]),  1,  50, PSF_x))\n",
    "                source_im = source_im.T\n",
    "                source_im[:,:] += profile\n",
    "                source_im = source_im.T\n",
    "\n",
    "            elif \"mNUV=\" in source:\n",
    "                #%%\n",
    "                mag=float(source.split(\"mNUV=\")[-1])\n",
    "                factor_lya = fraction_lya\n",
    "                flux = 10**(-(mag-20.08)/2.5)*2.06*1E-16/((6.62E-34*300000000/(wavelength*0.0000000001)/0.0000001))\n",
    "                elec_pix = flux * throughput * atm * self.QE * area /dispersion# should not be multiplied by self.exposure_time time here\n",
    "                with_line = elec_pix*(1-factor_lya) + factor_lya * (3700/1)*elec_pix* Gaussian1D.evaluate(np.arange(size[0]),  1,  size[0]/2,PSF_λ)/ Gaussian1D.evaluate(np.arange(size[0]),  1,  size[0]/2, PSF_λ).sum()\n",
    "                # source_im[50:55,:] += elec_pix #Gaussian2D.evaluate(x, y, flux, ly / 2, lx / 2, 100 * Ry, Rx, 0)\n",
    "                profile =  np.outer(with_line,Gaussian1D.evaluate(np.arange(size[1]),  1,  50, PSF_x) /Gaussian1D.evaluate(np.arange(size[1]),  1,  50, PSF_x))\n",
    "                source_im = source_im.T\n",
    "                source_im[:,:] += profile\n",
    "                source_im = source_im.T\n",
    "                # a = Table(data=([np.linspace(1500,2500,nsize2),np.zeros(nsize2)]),names=(\"WAVELENGTH\",\"e_pix_sec\"))\n",
    "                # a[\"e_pix_sec\"] = elec_pix*(1-factor_lya) + factor_lya * (3700/1)*elec_pix* Gaussian1D.evaluate(a[\"WAVELENGTH\"],  1,  line[\"wave\"], 8) \n",
    "                # f = interp1d(a[\"WAVELENGTH\"],a[\"e_pix_sec\"])\n",
    "                # profile =   Gaussian1D.evaluate(np.arange(nsize),  1,  nsize/2, Rx) /Gaussian1D.evaluate(np.arange(nsize),  1,  nsize/2, Rx).sum()\n",
    "                # subim = np.zeros((nsize2,nsize))\n",
    "                # wavelengths = np.linspace(2060-yi/dispersion,2060+(1000-yi)/dispersion,nsize2)\n",
    "                # source_im[int(xi-nsize/2):int(xi+nsize/2), OSregions[0] : OSregions[1]] +=  (subim+profile).T*f(wavelengths) * atm_trans(wavelengths) * self.QE(wavelengths)\n",
    "                # source_im_wo_atm[int(xi-nsize/2):int(xi+nsize/2), OSregions[0] : OSregions[1]] +=  (subim+profile).T*f(wavelengths) #* atm_trans(wavelengths)\n",
    "                \n",
    "            else:\n",
    "                # for file in glob.glob(\"/Users/Vincent/Downloads/FOS_spectra/FOS_spectra_for_FB/CIV/*.fits\"):\n",
    "                try:\n",
    "                    a = Table.read(\"Spectra/h_%sfos_spc.fits\"%(source.split(\" \")[1]))\n",
    "                    slits = None#Table.read(\"Targets/2022/\" + field).to_pandas()\n",
    "                    trans = Table.read(\"interpolate/transmission_pix_resolution.csv\")\n",
    "                    self.QE = Table.read(\"interpolate/self.QE_2022.csv\")\n",
    "                except FileNotFoundError: \n",
    "                    a = Table.read(\"/Users/Vincent/Github/notebooks/Spectra/h_%sfos_spc.fits\"%(source.split(\" \")[-1]))\n",
    "                    slits = Table.read(\"/Users/Vincent/Github/FireBallPipe/Calibration/Targets/2022/\" + field).to_pandas()\n",
    "                    trans = Table.read(\"/Users/Vincent/Github/FIREBall_IMO/Python Package/FireBallIMO-1.0/FireBallIMO/transmission_pix_resolution.csv\")\n",
    "                    self.QE = Table.read(\"interpolate/self.QE_2022.csv\")\n",
    "                self.QE = interp1d(self.QE[\"wave\"]*10,self.QE[\"self.QE_corr\"])#\n",
    "                trans[\"trans_conv\"] = np.convolve(trans[\"col2\"],np.ones(5)/5,mode=\"same\")\n",
    "                trans = trans[:-5]\n",
    "                atm_trans =  interp1d([1500,2500]+list(trans[\"col1\"]*10),[0,0] + list(trans[\"trans_conv\"]))#\n",
    "\n",
    "                a[\"photons\"] = a[\"FLUX\"]/9.93E-12   \n",
    "                a[\"e_pix_sec\"]  = a[\"photons\"] * throughput * atm  * area /dispersion\n",
    "                nsize,nsize2 = 100,500\n",
    "                source_im=np.zeros((nsize,nsize2))\n",
    "                source_im_wo_atm=np.zeros((nsize2,nsize))\n",
    "                mask = (a[\"WAVELENGTH\"]>1960) & (a[\"WAVELENGTH\"]<2280)\n",
    "                lmax = a[\"WAVELENGTH\"][mask][np.argmax( a[\"e_pix_sec\"][mask])]\n",
    "                # plt.plot( a[\"WAVELENGTH\"],a[\"e_pix_sec\"])\n",
    "                # plt.plot( a[\"WAVELENGTH\"][mask],a[\"e_pix_sec\"][mask])\n",
    "                f = interp1d(a[\"WAVELENGTH\"],a[\"e_pix_sec\"])#\n",
    "                profile =   Gaussian1D.evaluate(np.arange(nsize),  1,  nsize/2, Rx) /Gaussian1D.evaluate(np.arange(nsize),  1,  nsize/2, Rx).sum()\n",
    "                subim = np.zeros((nsize2,nsize))\n",
    "                wavelengths = np.linspace(lmax-nsize2/2/dispersion,lmax+nsize2/2/dispersion,nsize2)\n",
    "\n",
    "                if 1==0:\n",
    "                    # source_im=np.zeros((100,100))\n",
    "                    # # plt.plot(a[\"WAVELENGTH\"][mask],a[\"e_pix_exp\"][mask])\n",
    "                    # profile =   Gaussian1D.evaluate(np.arange(100),  1,  50, Rx) /Gaussian1D.evaluate(np.arange(100),  1,  50, Rx).sum()\n",
    "                    # i = np.argmin(abs(a[\"WAVELENGTH\"]-1960))\n",
    "                    # source_im[:,:] +=   profile\n",
    "                    # source_im = source_im.T*a[\"e_pix_sec\"][i:i+100]                    \n",
    "                    fig,(ax0,ax1,ax2) = plt.subplots(3,1)\n",
    "                    ax0.fill_between(wavelengths, profile.max()*f(wavelengths),profile.max()* f(wavelengths) * atm_trans(wavelengths),label=\"Atmosphere impact\",alpha=0.3)\n",
    "                    ax0.fill_between(wavelengths, profile.max()*f(wavelengths)* atm_trans(wavelengths)*self.QE(wavelengths),profile.max()* f(wavelengths) * atm_trans(wavelengths),label=\"self.QE impact\",alpha=0.3)\n",
    "                    ax1.plot(wavelengths,f(wavelengths)/f(wavelengths).ptp(),label=\"Spectra\")\n",
    "                    ax1.plot(wavelengths, f(wavelengths)* atm_trans(wavelengths)/(f(wavelengths)* atm_trans(wavelengths)).ptp(),label=\"Spectra * Atm\")\n",
    "                    ax1.plot(wavelengths, f(wavelengths)* atm_trans(wavelengths)*self.QE(wavelengths)/( f(wavelengths)* atm_trans(wavelengths)*self.QE(wavelengths)).ptp(),label=\"Spectra * Atm * self.QE\")\n",
    "                    ax2.plot(wavelengths,atm_trans(wavelengths) ,label=\"Atmosphere\")\n",
    "                    ax2.plot(wavelengths,self.QE(wavelengths) ,label=\"self.QE\")\n",
    "                    ax0.legend()\n",
    "                    ax1.legend()\n",
    "                    ax2.legend()\n",
    "                    ax0.set_ylabel(\"e/pix/sec\")\n",
    "                    ax1.set_ylabel(\"Moself.RNalized prof\")\n",
    "                    ax2.set_ylabel(\"%\")\n",
    "                    ax2.set_xlabel(\"wavelength\")\n",
    "                    ax0.set_title(source.split(\" \")[-1])\n",
    "                    fig.savefig(\"/Users/Vincent/Github/notebooks/Spectra/h_%sfos_spc.png\"%(source.split(\" \")[-1]))\n",
    "                    plt.show()\n",
    "                self.QE = self.QE(wavelengths) if self.QElambda else self.QE(lmax) \n",
    "                atm_trans = atm_trans(wavelengths) if atmlambda else atm_trans(lmax) \n",
    "                source_im[:,:] +=  (subim+profile).T*f(wavelengths) * atm_trans * self.QE\n",
    "                # source_im_wo_atm[:,:] +=  (subim+profile).T*f(wavelengths) #* atm_trans(wavelengths)\n",
    "        source_im = self.Dark_current_f  + self.sky +  source_im  * int(self.exposure_time)\n",
    "        source_im_wo_atm = self.Dark_current_f  + self.sky  + source_im_wo_atm * int(self.exposure_time)\n",
    "        y_pix=1000\n",
    "        # print(len(source_im),source_im.shape)\n",
    "        self.long = False\n",
    "        if (self.readout_time/self.exposure_time > 0.2) & (self.long):\n",
    "            print(source_im)\n",
    "            cube = np.array([(self.readout_time/self.exposure_time/y_pix)*np.vstack((np.zeros((i,len(source_im))),source_im[::-1,:][:-i,:]))[::-1,:] for i in np.arange(1,len(source_im))],dtype=float)\n",
    "            source_im = source_im+np.sum(cube,axis=0)\n",
    "        if self.cosmic_ray_loss_per_sec is None:\n",
    "            self.cosmic_ray_loss_per_sec = np.minimum(0.005*(self.exposure_time+self.readout_time/2),1)#+self.readout_time/2\n",
    "        stack = np.max([int(stack * (1-self.cosmic_ray_loss_per_sec)),1])\n",
    "        cube_stack = -np.ones((int(stack),size[1], size[0]), dtype=\"int32\")\n",
    "\n",
    "        # print(self.cosmic_ray_loss_per_sec)\n",
    "        n_smearing=6\n",
    "        # image[:, OSregions[0] : OSregions[1]] += source_im\n",
    "        # print(image[:, OSregions[0] : OSregions[1]].shape,source_im.shape)\n",
    "        image[:, OSregions[0] : OSregions[1]] += np.random.gamma( np.random.poisson(source_im) + np.array(np.random.rand(size[1], OSregions[1]-OSregions[0])<self.CIC_charge,dtype=int) , self.EM_gain)\n",
    "        # take into acount CR losses\n",
    "        #18%\n",
    "        # image_stack[:, OSregions[0] : OSregions[1]] = np.nanmean([np.where(np.random.rand(size[1], OSregions[1]-OSregions[0]) < self.cosmic_ray_loss_per_sec/n_smearing,np.nan,1) * (np.random.gamma(np.random.poisson(source_im)  + np.array(np.random.rand(size[1], OSregions[1]-OSregions[0])<self.CIC_charge,dtype=int) , self.EM_gain)) for i in range(int(stack))],axis=0)\n",
    "        image_stack[:, OSregions[0] : OSregions[1]] = np.mean([(np.random.gamma(np.random.poisson(source_im)  + np.array(np.random.rand(size[1], OSregions[1]-OSregions[0])<self.CIC_charge,dtype=int) , self.EM_gain)) for i in range(int(stack))],axis=0)\n",
    "        \n",
    "        # a = (np.where(np.random.rand(int(stack), size[1],OSregions[1]-OSregions[0]) < self.cosmic_ray_loss_per_sec/n_smearing,np.nan,1) * np.array([ (np.random.gamma(np.random.poisson(source_im)  + np.array(np.random.rand( OSregions[1]-OSregions[0],size[1]).T<self.CIC_charge,dtype=int) , self.EM_gain))  for i in range(int(stack))]))\n",
    "        # Addition of the phyical image on the 2 overscan regions\n",
    "        #image += source_im2\n",
    "        if p_sCIC>0:\n",
    "            image +=  np.random.gamma( np.array(np.random.rand(size[1], size[0])<p_sCIC,dtype=int) , np.random.randint(1, n_registers, size=image.shape))\n",
    "            #30%\n",
    "            image_stack += np.random.gamma( np.array(np.random.rand(size[1], size[0])<int(stack)*p_sCIC,dtype=int) , np.random.randint(1, n_registers, size=image.shape))\n",
    "        if self.counting_mode:\n",
    "            a = np.array([ (np.random.gamma(np.random.poisson(source_im)  + np.array(np.random.rand( OSregions[1]-OSregions[0],size[1]).T<self.CIC_charge,dtype=\"int32\") , self.EM_gain))  for i in range(int(stack))])\n",
    "            cube_stack[:,:, OSregions[0] : OSregions[1]] = a\n",
    "            cube_stack += np.random.gamma( np.array(np.random.rand(int(stack),size[1], size[0])<int(stack)*p_sCIC,dtype=int) , np.random.randint(1, n_registers, size=image.shape)).astype(\"int32\")\n",
    "        #         # addition of pCIC (stil need to add sCIC before EM registers)\n",
    "        #         prob_pCIC = np.random.rand(size[1], size[0])  # Draw a number prob in [0,1]\n",
    "        #         image[prob_pCIC < self.CIC_charge] += 1\n",
    "        #         source_im2_stack[prob_pCIC < p_pCIC*stack] += 1\n",
    "\n",
    "        #         # EM amp (of source + self.Dard_current + pCIC)\n",
    "        #         id_nnul = image != 0\n",
    "        #         image[id_nnul] = np.random.gamma(image[id_nnul], self.EM_gain)\n",
    "                # Addition of sCIC inside EM registers (ie partially amplified)\n",
    "        #         prob_sCIC = np.random.rand(size[1], size[0])  # Draw a number prob in [0,1]\n",
    "        #         id_scic = prob_sCIC < p_sCIC  # sCIC positions\n",
    "        #         # partial amplification of sCIC\n",
    "        #         register = np.random.randint(1, n_registers, size=id_scic.sum())  # Draw at which stage of the EM register the electoself.RN is created\n",
    "        #         image[id_scic] += np.random.exponential(np.power(self.EM_gain, register / n_registers))\n",
    "            # semaring post EM amp (sgest noise reduction)\n",
    "            #TODO must add self.smearing for cube!\n",
    "        if self.smearing > 0:\n",
    "            # self.smearing dependant on flux\n",
    "            #2%\n",
    "            smearing_kernels = variable_smearing_kernels(image, self.smearing, SmearExpDecrement)\n",
    "            offsets = np.arange(n_smearing)\n",
    "            A = dia_matrix((smearing_kernels.reshape((n_smearing, -1)), offsets), shape=(image.size, image.size))\n",
    "\n",
    "            image = A.dot(image.ravel()).reshape(image.shape)\n",
    "            image_stack = A.dot(image_stack.ravel()).reshape(image_stack.shape)\n",
    "        #     if self.readout_time > 0:\n",
    "        #         # self.smearing dependant on flux\n",
    "        #         self.smearing_kernels = variable_smearing.smearing_keself.RNels(image.T, self.readout_time, SmearExpDecrement)#.swapaxes(1,2)\n",
    "        #         offsets = np.arange(n_smearing)\n",
    "        #         A = dia_matrix((self.smearing_kernels.reshape((n_smearing, -1)), offsets), shape=(image.size, image.size))#.swapaxes(0,1)\n",
    "        #         image = A.dot(image.ravel()).reshape(image.shape)#.T\n",
    "        #         image_stack = A.dot(image_stack.ravel()).reshape(image_stack.shape)#.T\n",
    "        type_ = \"int32\"\n",
    "        type_ = \"float64\"\n",
    "        readout = np.random.normal(Bias, self.RN, (size[1], size[0]))\n",
    "        readout_stack = np.random.normal(Bias, self.RN/np.sqrt(int(stack)), (size[1], size[0]))\n",
    "        if self.counting_mode:\n",
    "            readout_cube = np.random.normal(Bias, self.RN, (int(stack),size[1], size[0])).astype(\"int32\")\n",
    "            # print((np.random.rand(source_im.shape[0], source_im.shape[1]) < self.cosmic_ray_loss_per_sec).mean())\n",
    "            #TOKEEP  for cosmic ray masking readout[np.random.rand(source_im.shape[0], source_im.shape[1]) < self.cosmic_ray_loss_per_sec]=np.nan\n",
    "            #print(np.max(((image + readout) * ConversionGain).round()))\n",
    "        #     if np.max(((image + readout) * ConversionGain).round()) > 2 ** 15:\n",
    "        imaADU_wo_RN = (image * ConversionGain).round().astype(type_)\n",
    "        imaADU_RN = (readout * ConversionGain).round().astype(type_)\n",
    "        imaADU = ((image + 1*readout) * ConversionGain).round().astype(type_)\n",
    "        imaADU_stack = ((image_stack + 1*readout_stack) * ConversionGain).round().astype(type_)\n",
    "        if self.counting_mode:\n",
    "            imaADU_cube = ((cube_stack + 1*readout_cube) * ConversionGain).round().astype(\"int32\")\n",
    "        else:\n",
    "            imaADU_cube = imaADU_stack\n",
    "        return imaADU, imaADU_stack, imaADU_cube, source_im, source_im_wo_atm#imaADU_wo_RN, imaADU_RN\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    FB = Observation().SimulateFIREBallemCCDImage(conv_gain=0.53,  Bias=\"Auto\",  p_sCIC=0,  SmearExpDecrement=50000,  source=\"Slit\", size=[100, 100], OSregions=[0, 100], name=\"Auto\", spectra=\"-\", cube=\"-\", n_registers=604, save=False, field=\"targets_F2.csv\",QElambda=True,atmlambda=True,fraction_lya=0.05)\n",
    "# %%\n",
    "\n",
    "\n",
    "# %%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
